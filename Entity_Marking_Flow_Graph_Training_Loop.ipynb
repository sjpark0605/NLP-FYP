{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjpark0605/NLP-FYP/blob/main/Entity_Marking_Flow_Graph_Training_Loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN3-DEysN7Mx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets evaluate transformers[sentencepiece] accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRZ2cKCHN7tM"
      },
      "outputs": [],
      "source": [
        "# Imports for Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_from_disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEnNzeY1N0Tt"
      },
      "outputs": [],
      "source": [
        "project_dir = '/content/drive/MyDrive/COMP0029/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8K7Aau1r__u"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UszZa5GNvPS"
      },
      "outputs": [],
      "source": [
        "corpus_datasets = load_from_disk(project_dir + 'datasets/english-recipe-entity-marked-flow-graph')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "tokenizer.add_tokens(['<e1>', '</e1>', '<e2>', '</e2>'], special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNr03VRZnV8T",
        "outputId": "7f1e038f-c186-4ec3-8e21-3f0611962582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxGQezlonyOz",
        "outputId": "33b9d6bd-a0eb-4744-ca12-04bbce4db590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['First Sentence', 'Second Sentence', 'Label'],\n",
              "        num_rows: 49123\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['First Sentence', 'Second Sentence', 'Label'],\n",
              "        num_rows: 12281\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus_datasets['train']['Second Sentence'][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH9GrKPb6Fty",
        "outputId": "606d1223-3b8a-484f-993c-939a88a8271d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<e2> Season </e2> with salt ;', 'Split the <e2> layers </e2> of cooled cake horizontally , cover the top of each layer with icing , then stack them onto a serving plate .', 'Place covered dish in oven at <e2> Gas Mark 5 </e2> ( 375 degrees Fahrenheit/190 degrees Centigrade ) for about 2 hours ( removing every half hour to stir ) .', None, 'Stir-fry the garlic and <e2> shallots </e2> until fragrant , 3-4 minutes .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAY16LGkNWOz"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(data):\n",
        "  if data[\"Second Sentence\"] is None:\n",
        "    return tokenizer(data[\"First Sentence\"], add_special_tokens=True, max_length=128, padding='max_length')\n",
        "  return tokenizer(data[\"First Sentence\"], data[\"Second Sentence\"], add_special_tokens=True, max_length=128, padding='max_length')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RJUeLizNbQn",
        "outputId": "722f4443-91dc-4d47-c57f-b8b6c6e5c194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /content/drive/MyDrive/COMP0029/datasets/english-recipe-entity-marked-flow-graph/train/cache-fe3d4715b4f8b627.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /content/drive/MyDrive/COMP0029/datasets/english-recipe-entity-marked-flow-graph/valid/cache-08213c3932e9aa26.arrow\n"
          ]
        }
      ],
      "source": [
        "tokenized_datasets = corpus_datasets.map(tokenize_function, batched=False)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets[\"train\"][\"First Sentence\"][12])\n",
        "print(tokenized_datasets[\"train\"][\"Second Sentence\"][12])\n",
        "\n",
        "print(tokenizer.convert_ids_to_tokens(tokenized_datasets[\"train\"][\"input_ids\"][12]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fhu1jww0IjE",
        "outputId": "1e0daaae-8b3d-493f-cd74-79f1cdfd04c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a large bowl , <e1> mix together </e1> the pumpkin puree , 3 eggs , <e2> 100g </e2> caster sugar , dark brown soft sugar and cinnamon .\n",
            "None\n",
            "['[CLS]', 'in', 'a', 'large', 'bowl', ',', '<e1>', 'mix', 'together', '</e1>', 'the', 'pumpkin', 'pure', '##e', ',', '3', 'eggs', ',', '<e2>', '100', '##g', '</e2>', 'caste', '##r', 'sugar', ',', 'dark', 'brown', 'soft', 'sugar', 'and', 'cinnamon', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAVlYNK3NcuR",
        "outputId": "cf2daf52-30c1-4e0b-e4e4-d00b68479067"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"First Sentence\", \"Second Sentence\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"Label\", \"labels\")\n",
        "\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgcj3nAGNdz2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=64, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"valid\"], batch_size=64, collate_fn=data_collator\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od5Rn2FtNgbR",
        "outputId": "5e6bd285-26a1-4454-b4f9-0f12e9c78f53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a-eq:LR',\n",
              " 'a-eq:RL',\n",
              " 'a:LR',\n",
              " 'a:RL',\n",
              " 'd:LR',\n",
              " 'd:RL',\n",
              " 'f-comp:LR',\n",
              " 'f-comp:RL',\n",
              " 'f-eq:LR',\n",
              " 'f-eq:RL',\n",
              " 'f-part-of:LR',\n",
              " 'f-part-of:RL',\n",
              " 'f-set:LR',\n",
              " 'f-set:RL',\n",
              " 'non-edge',\n",
              " 'o:LR',\n",
              " 'o:RL',\n",
              " 't-comp:LR',\n",
              " 't-comp:RL',\n",
              " 't-eq:LR',\n",
              " 't-eq:RL',\n",
              " 't-part-of:LR',\n",
              " 't-part-of:RL',\n",
              " 't:LR',\n",
              " 't:RL',\n",
              " 'v-tm:LR',\n",
              " 'v-tm:RL']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "label_names = tokenized_datasets[\"train\"].features[\"labels\"].names\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5ABMSQMtkNZ"
      },
      "outputs": [],
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_olu76eNhnS"
      },
      "outputs": [],
      "source": [
        "#import evaluate\n",
        "\n",
        "#metric = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqUVymJjNixh"
      },
      "outputs": [],
      "source": [
        "def postprocess(predictions, labels):\n",
        "    predictions = predictions.detach().cpu().clone().numpy()\n",
        "    labels = labels.detach().cpu().clone().numpy()\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_predictions = [[label_names[prediction]] for prediction in predictions]\n",
        "    true_labels = [[label_names[label]] for label in labels]\n",
        "\n",
        "    return true_predictions, true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6jlIXgJNkDJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    flow_model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        inputs = {\n",
        "                  'input_ids':      batch['input_ids'],\n",
        "                  'attention_mask': batch['attention_mask'],\n",
        "                  'labels':         batch['labels'],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = flow_model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXqkhN3DNm7F"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {index: label for index, label in enumerate(label_names)}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muTR16rfjYxi",
        "outputId": "21e00725-1414-43bf-f137-9c94add6cb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.6180e-03, 9.0909e-02, 1.9685e-03, 3.2258e-02, 1.3141e-03, 1.1111e-03,\n",
              "        9.0909e-02, 4.5872e-03, 1.1299e-03, 3.7037e-02, 1.9455e-03, 1.3158e-02,\n",
              "        9.0909e-02, 1.4286e-01, 2.7447e-05, 9.9206e-04, 8.2440e-04, 1.2195e-02,\n",
              "        2.2831e-03, 3.9841e-03, 5.0000e-01, 8.8496e-03, 2.5641e-02, 6.7249e-04,\n",
              "        2.9360e-04, 2.0408e-02, 2.1598e-03], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Calculate Weights for Cross Entropy Loss\n",
        "num_labels = len(label_names)\n",
        "frequencies = [0] * num_labels\n",
        "\n",
        "for batch in train_dataloader:\n",
        "  for label in batch['labels']:\n",
        "      frequencies[label] += 1\n",
        "\n",
        "weights = [0.] * num_labels\n",
        "\n",
        "# total_samples = sum(frequencies)\n",
        "for i in range(num_labels):\n",
        "    weights[i] = 1 / frequencies[i]\n",
        "\n",
        "weights = torch.tensor(weights).to(device)\n",
        "# weights /= weights.sum()\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
        "from sklearn.metrics import f1_score\n",
        "from torch import nn\n",
        "\n",
        "accelerator = Accelerator()\n",
        "\n",
        "flow_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint, \n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    num_labels=len(label_names)\n",
        ")\n",
        "\n",
        "flow_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "param_optimizer = list(flow_model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}]\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
        "\n",
        "# optimizer = torch.optim.AdamW(flow_model.parameters(), lr=3e-5)\n",
        "\n",
        "train_dl, eval_dl, flow_model, optimizer = accelerator.prepare(\n",
        "    train_dataloader, eval_dataloader, flow_model, optimizer\n",
        ")\n",
        "\n",
        "loss_fct = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "print(flow_model.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_w7W5sa_fyl",
        "outputId": "485b2a46-2e61-43c1-e2bc-70ecf4561a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"a-eq:LR\",\n",
            "    \"1\": \"a-eq:RL\",\n",
            "    \"2\": \"a:LR\",\n",
            "    \"3\": \"a:RL\",\n",
            "    \"4\": \"d:LR\",\n",
            "    \"5\": \"d:RL\",\n",
            "    \"6\": \"f-comp:LR\",\n",
            "    \"7\": \"f-comp:RL\",\n",
            "    \"8\": \"f-eq:LR\",\n",
            "    \"9\": \"f-eq:RL\",\n",
            "    \"10\": \"f-part-of:LR\",\n",
            "    \"11\": \"f-part-of:RL\",\n",
            "    \"12\": \"f-set:LR\",\n",
            "    \"13\": \"f-set:RL\",\n",
            "    \"14\": \"non-edge\",\n",
            "    \"15\": \"o:LR\",\n",
            "    \"16\": \"o:RL\",\n",
            "    \"17\": \"t-comp:LR\",\n",
            "    \"18\": \"t-comp:RL\",\n",
            "    \"19\": \"t-eq:LR\",\n",
            "    \"20\": \"t-eq:RL\",\n",
            "    \"21\": \"t-part-of:LR\",\n",
            "    \"22\": \"t-part-of:RL\",\n",
            "    \"23\": \"t:LR\",\n",
            "    \"24\": \"t:RL\",\n",
            "    \"25\": \"v-tm:LR\",\n",
            "    \"26\": \"v-tm:RL\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"a-eq:LR\": 0,\n",
            "    \"a-eq:RL\": 1,\n",
            "    \"a:LR\": 2,\n",
            "    \"a:RL\": 3,\n",
            "    \"d:LR\": 4,\n",
            "    \"d:RL\": 5,\n",
            "    \"f-comp:LR\": 6,\n",
            "    \"f-comp:RL\": 7,\n",
            "    \"f-eq:LR\": 8,\n",
            "    \"f-eq:RL\": 9,\n",
            "    \"f-part-of:LR\": 10,\n",
            "    \"f-part-of:RL\": 11,\n",
            "    \"f-set:LR\": 12,\n",
            "    \"f-set:RL\": 13,\n",
            "    \"non-edge\": 14,\n",
            "    \"o:LR\": 15,\n",
            "    \"o:RL\": 16,\n",
            "    \"t-comp:LR\": 17,\n",
            "    \"t-comp:RL\": 18,\n",
            "    \"t-eq:LR\": 19,\n",
            "    \"t-eq:RL\": 20,\n",
            "    \"t-part-of:LR\": 21,\n",
            "    \"t-part-of:RL\": 22,\n",
            "    \"t:LR\": 23,\n",
            "    \"t:RL\": 24,\n",
            "    \"v-tm:LR\": 25,\n",
            "    \"v-tm:RL\": 26\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.27.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30526\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c87ed0a7d4943adbb98ac64e93a6d08",
            "9f15aa55f1244c2f9c6c743a662dd0fa",
            "82c749109b874b33911f7436086182b7",
            "6524698e55e445a1a83d998277d034ce",
            "19725ffb27e044ca923c86d5f6bbef28",
            "e6c379ef96c149ecb3bfd992ecdaf726",
            "dd3de8e79f1f409c865b3e152aefefe2",
            "a66f0c9c09074058bca4f82b3403ff84",
            "b2755a32e58445a3afb870ec3f6ba2bb",
            "57e84b0e566b4ee4acb1256e19401ef0",
            "88976ac245fa496bb8e5963010fcf25a"
          ]
        },
        "id": "jqmj8aHuNoCU",
        "outputId": "fe333186-54e3-4e09-9e6d-22ff89da18f4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c87ed0a7d4943adbb98ac64e93a6d08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7680 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3079016208648682\n",
            "Training loss: 1.1348644495010376\n",
            "Training loss: 1.2271782159805298\n",
            "Training loss: 0.5608022809028625\n",
            "Training loss: 0.7859618663787842\n",
            "Training loss: 0.9551581144332886\n",
            "Training loss: 0.6585026383399963\n",
            "Training loss: 1.1674813032150269\n",
            "Training loss: 0.45428845286369324\n",
            "Training loss: 0.6169338226318359\n",
            "Training loss: 0.5855906009674072\n",
            "Training loss: 0.6160440444946289\n",
            "Training loss: 0.8316535949707031\n",
            "Training loss: 1.0070163011550903\n",
            "Training loss: 0.7390241026878357\n",
            "Training loss: 0.5796247124671936\n",
            "Training loss: 0.5851195454597473\n",
            "Training loss: 0.3028911352157593\n",
            "Training loss: 0.6106656193733215\n",
            "Training loss: 0.6108065843582153\n",
            "Training loss: 0.7276121973991394\n",
            "Training loss: 0.4235355854034424\n",
            "Training loss: 0.3937338590621948\n",
            "Training loss: 0.27413272857666016\n",
            "Training loss: 0.4686310887336731\n",
            "Training loss: 0.265854150056839\n",
            "Training loss: 0.3728793263435364\n",
            "Training loss: 0.5601999163627625\n",
            "Training loss: 0.28741252422332764\n",
            "Training loss: 0.5128347277641296\n",
            "Training loss: 0.39758408069610596\n",
            "Training loss: 0.3971996009349823\n",
            "Training loss: 0.4374276399612427\n",
            "Training loss: 0.6405181288719177\n",
            "Training loss: 0.4476562440395355\n",
            "Training loss: 0.38821762800216675\n",
            "Training loss: 0.3972221314907074\n",
            "Training loss: 0.4707457423210144\n",
            "Class: a-eq:LR\n",
            "Accuracy: 0/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 98/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 0/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 88/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 181/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 39/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 26/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 0/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 0/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8305/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 226/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 243/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 0/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 70/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 0/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 0/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 0/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 303/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 781/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 0/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 108/116\n",
            "\n",
            "Validation loss: 0.527469456118221\n",
            "F1 Score (Weighted): 0.846314781745269\n",
            "None\n",
            "Training loss: 0.35978788137435913\n",
            "Training loss: 0.33144325017929077\n",
            "Training loss: 0.35256269574165344\n",
            "Training loss: 0.49788138270378113\n",
            "Training loss: 0.2723337411880493\n",
            "Training loss: 0.35695207118988037\n",
            "Training loss: 0.32395073771476746\n",
            "Training loss: 0.40116560459136963\n",
            "Training loss: 0.36839771270751953\n",
            "Training loss: 0.2753877639770508\n",
            "Training loss: 0.3682267665863037\n",
            "Training loss: 0.3412033021450043\n",
            "Training loss: 0.4440336525440216\n",
            "Training loss: 0.33466365933418274\n",
            "Training loss: 0.37444907426834106\n",
            "Training loss: 0.36586248874664307\n",
            "Training loss: 0.32752445340156555\n",
            "Training loss: 0.5036078095436096\n",
            "Training loss: 0.48880502581596375\n",
            "Training loss: 0.2515738010406494\n",
            "Training loss: 0.12392020970582962\n",
            "Training loss: 0.3691580295562744\n",
            "Training loss: 0.19506333768367767\n",
            "Training loss: 0.26949819922447205\n",
            "Training loss: 0.42154398560523987\n",
            "Training loss: 0.311019629240036\n",
            "Training loss: 0.23831132054328918\n",
            "Training loss: 0.35387375950813293\n",
            "Training loss: 0.2982475757598877\n",
            "Training loss: 0.11326579749584198\n",
            "Training loss: 0.2938195466995239\n",
            "Training loss: 0.17169244587421417\n",
            "Training loss: 0.16252818703651428\n",
            "Training loss: 0.375487744808197\n",
            "Training loss: 0.2723907232284546\n",
            "Training loss: 0.3841080665588379\n",
            "Training loss: 0.31295299530029297\n",
            "Training loss: 0.1761595904827118\n",
            "Class: a-eq:LR\n",
            "Accuracy: 0/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 97/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 0/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 172/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 180/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 48/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 70/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 60/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 9/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8337/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 230/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 232/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 0/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 79/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 15/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 4/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 7/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 294/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 782/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 7/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 111/116\n",
            "\n",
            "Validation loss: 0.40949384588748217\n",
            "F1 Score (Weighted): 0.877478479510023\n",
            "None\n",
            "Training loss: 0.2691352069377899\n",
            "Training loss: 0.3088917136192322\n",
            "Training loss: 0.3875981271266937\n",
            "Training loss: 0.39763933420181274\n",
            "Training loss: 0.4885409474372864\n",
            "Training loss: 0.25271156430244446\n",
            "Training loss: 0.14886243641376495\n",
            "Training loss: 0.21555006504058838\n",
            "Training loss: 0.22633671760559082\n",
            "Training loss: 0.1638195514678955\n",
            "Training loss: 0.1884489208459854\n",
            "Training loss: 0.3411731719970703\n",
            "Training loss: 0.13049446046352386\n",
            "Training loss: 0.2297850400209427\n",
            "Training loss: 0.17145128548145294\n",
            "Training loss: 0.15688954293727875\n",
            "Training loss: 0.2661769688129425\n",
            "Training loss: 0.4085766077041626\n",
            "Training loss: 0.2257893979549408\n",
            "Training loss: 0.2683001756668091\n",
            "Training loss: 0.10260184109210968\n",
            "Training loss: 0.27165594696998596\n",
            "Training loss: 0.2677442133426666\n",
            "Training loss: 0.2445780634880066\n",
            "Training loss: 0.154952734708786\n",
            "Training loss: 0.2170451581478119\n",
            "Training loss: 0.3618448078632355\n",
            "Training loss: 0.23338107764720917\n",
            "Training loss: 0.19029174745082855\n",
            "Training loss: 0.3228093385696411\n",
            "Training loss: 0.16679923236370087\n",
            "Training loss: 0.1485985368490219\n",
            "Training loss: 0.16660119593143463\n",
            "Training loss: 0.26962998509407043\n",
            "Training loss: 0.06842990219593048\n",
            "Training loss: 0.3039146661758423\n",
            "Training loss: 0.23006077110767365\n",
            "Training loss: 0.12372417002916336\n",
            "Training loss: 0.48730790615081787\n",
            "Class: a-eq:LR\n",
            "Accuracy: 0/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 109/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 0/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 152/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 183/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 42/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 115/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 58/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 15/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8276/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 233/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 245/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 2/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 74/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 12/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 9/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 8/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 314/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 800/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 10/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 112/116\n",
            "\n",
            "Validation loss: 0.39104176479546976\n",
            "F1 Score (Weighted): 0.8814232843656481\n",
            "None\n",
            "Training loss: 0.11047276109457016\n",
            "Training loss: 0.21119843423366547\n",
            "Training loss: 0.09594220668077469\n",
            "Training loss: 0.16122372448444366\n",
            "Training loss: 0.09971310943365097\n",
            "Training loss: 0.14459696412086487\n",
            "Training loss: 0.21549876034259796\n",
            "Training loss: 0.07938262075185776\n",
            "Training loss: 0.19550611078739166\n",
            "Training loss: 0.11577131599187851\n",
            "Training loss: 0.3423211872577667\n",
            "Training loss: 0.16186752915382385\n",
            "Training loss: 0.2581751048564911\n",
            "Training loss: 0.1648724228143692\n",
            "Training loss: 0.3623400330543518\n",
            "Training loss: 0.1472322642803192\n",
            "Training loss: 0.11318571120500565\n",
            "Training loss: 0.18169978260993958\n",
            "Training loss: 0.08064483106136322\n",
            "Training loss: 0.2577096223831177\n",
            "Training loss: 0.2294921725988388\n",
            "Training loss: 0.2728983461856842\n",
            "Training loss: 0.3317364454269409\n",
            "Training loss: 0.1675899177789688\n",
            "Training loss: 0.1760444939136505\n",
            "Training loss: 0.2357180416584015\n",
            "Training loss: 0.10853968560695648\n",
            "Training loss: 0.12328827381134033\n",
            "Training loss: 0.21508899331092834\n",
            "Training loss: 0.11729035526514053\n",
            "Training loss: 0.09584283083677292\n",
            "Training loss: 0.13562272489070892\n",
            "Training loss: 0.23720720410346985\n",
            "Training loss: 0.09835129231214523\n",
            "Training loss: 0.3192765712738037\n",
            "Training loss: 0.16720393300056458\n",
            "Training loss: 0.19635112583637238\n",
            "Training loss: 0.1631949543952942\n",
            "Class: a-eq:LR\n",
            "Accuracy: 0/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 87/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 0/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 168/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 187/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 43/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 130/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 74/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 16/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8211/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 225/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 232/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 3/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 75/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 34/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 9/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 9/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 310/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 808/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 9/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 112/116\n",
            "\n",
            "Validation loss: 0.404647329589352\n",
            "F1 Score (Weighted): 0.88259521695803\n",
            "None\n",
            "Training loss: 0.07518725097179413\n",
            "Training loss: 0.15709589421749115\n",
            "Training loss: 0.15792135894298553\n",
            "Training loss: 0.07319722324609756\n",
            "Training loss: 0.14296771585941315\n",
            "Training loss: 0.11587204784154892\n",
            "Training loss: 0.10831392556428909\n",
            "Training loss: 0.19430747628211975\n",
            "Training loss: 0.12180712819099426\n",
            "Training loss: 0.14775465428829193\n",
            "Training loss: 0.07609403878450394\n",
            "Training loss: 0.07883040606975555\n",
            "Training loss: 0.1644529402256012\n",
            "Training loss: 0.1369907408952713\n",
            "Training loss: 0.08912700414657593\n",
            "Training loss: 0.07168900221586227\n",
            "Training loss: 0.06027337163686752\n",
            "Training loss: 0.06673991680145264\n",
            "Training loss: 0.19962310791015625\n",
            "Training loss: 0.10888929665088654\n",
            "Training loss: 0.3127850592136383\n",
            "Training loss: 0.16806650161743164\n",
            "Training loss: 0.17954754829406738\n",
            "Training loss: 0.12052791565656662\n",
            "Training loss: 0.13005751371383667\n",
            "Training loss: 0.21165896952152252\n",
            "Training loss: 0.05321405827999115\n",
            "Training loss: 0.09538750350475311\n",
            "Training loss: 0.17485013604164124\n",
            "Training loss: 0.08040372282266617\n",
            "Training loss: 0.17909465730190277\n",
            "Training loss: 0.1548856496810913\n",
            "Training loss: 0.2602391242980957\n",
            "Training loss: 0.14938917756080627\n",
            "Training loss: 0.08554231375455856\n",
            "Training loss: 0.07763026654720306\n",
            "Training loss: 0.32120370864868164\n",
            "Training loss: 0.07759025692939758\n",
            "Training loss: 0.0505729503929615\n",
            "Class: a-eq:LR\n",
            "Accuracy: 0/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 100/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 0/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 166/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 190/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 39/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 98/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 76/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 16/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8398/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 228/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 241/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 3/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 80/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 18/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 12/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 9/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 312/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 810/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 10/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 111/116\n",
            "\n",
            "Validation loss: 0.3882375551232447\n",
            "F1 Score (Weighted): 0.8918383943290343\n",
            "None\n",
            "Training loss: 0.06641912460327148\n",
            "Training loss: 0.042213525623083115\n",
            "Training loss: 0.10841328650712967\n",
            "Training loss: 0.08347847312688828\n",
            "Training loss: 0.11674375087022781\n",
            "Training loss: 0.19998851418495178\n",
            "Training loss: 0.06448261439800262\n",
            "Training loss: 0.07408405840396881\n",
            "Training loss: 0.15633279085159302\n",
            "Training loss: 0.10394012928009033\n",
            "Training loss: 0.04526222497224808\n",
            "Training loss: 0.11518967151641846\n",
            "Training loss: 0.10975362360477448\n",
            "Training loss: 0.055213309824466705\n",
            "Training loss: 0.05911598727107048\n",
            "Training loss: 0.06408506631851196\n",
            "Training loss: 0.05911397188901901\n",
            "Training loss: 0.029248259961605072\n",
            "Training loss: 0.07053276896476746\n",
            "Training loss: 0.07427307963371277\n",
            "Training loss: 0.17417293787002563\n",
            "Training loss: 0.1332283318042755\n",
            "Training loss: 0.10381567478179932\n",
            "Training loss: 0.2049754410982132\n",
            "Training loss: 0.0702148973941803\n",
            "Training loss: 0.1419200897216797\n",
            "Training loss: 0.06530876457691193\n",
            "Training loss: 0.08294056355953217\n",
            "Training loss: 0.04297575354576111\n",
            "Training loss: 0.1924830824136734\n",
            "Training loss: 0.23103733360767365\n",
            "Training loss: 0.12635155022144318\n",
            "Training loss: 0.2113083153963089\n",
            "Training loss: 0.03942260891199112\n",
            "Training loss: 0.08558565378189087\n",
            "Training loss: 0.08962475508451462\n",
            "Training loss: 0.17152994871139526\n",
            "Training loss: 0.17781220376491547\n",
            "Class: a-eq:LR\n",
            "Accuracy: 0/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 82/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 0/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 163/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 176/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 39/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 118/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 43/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 14/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8556/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 233/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 243/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 6/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 89/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 37/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 11/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 8/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 301/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 793/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 11/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 110/116\n",
            "\n",
            "Validation loss: 0.3601871778179581\n",
            "F1 Score (Weighted): 0.899021725307172\n",
            "None\n",
            "Training loss: 0.12069524079561234\n",
            "Training loss: 0.05827763304114342\n",
            "Training loss: 0.18444085121154785\n",
            "Training loss: 0.02297206223011017\n",
            "Training loss: 0.05809909477829933\n",
            "Training loss: 0.0697232186794281\n",
            "Training loss: 0.09444325417280197\n",
            "Training loss: 0.1957581788301468\n",
            "Training loss: 0.065375916659832\n",
            "Training loss: 0.036549657583236694\n",
            "Training loss: 0.07624321430921555\n",
            "Training loss: 0.07380781322717667\n",
            "Training loss: 0.07651294767856598\n",
            "Training loss: 0.1112816110253334\n",
            "Training loss: 0.01936337910592556\n",
            "Training loss: 0.17547130584716797\n",
            "Training loss: 0.02544466406106949\n",
            "Training loss: 0.1238245740532875\n",
            "Training loss: 0.1406850814819336\n",
            "Training loss: 0.08108394593000412\n",
            "Training loss: 0.059285968542099\n",
            "Training loss: 0.1292109191417694\n",
            "Training loss: 0.07627826184034348\n",
            "Training loss: 0.07535000890493393\n",
            "Training loss: 0.13157832622528076\n",
            "Training loss: 0.018423838540911674\n",
            "Training loss: 0.05817034840583801\n",
            "Training loss: 0.07293140143156052\n",
            "Training loss: 0.053006626665592194\n",
            "Training loss: 0.1470942348241806\n",
            "Training loss: 0.06318516284227371\n",
            "Training loss: 0.1574583351612091\n",
            "Training loss: 0.14382940530776978\n",
            "Training loss: 0.02776324935257435\n",
            "Training loss: 0.13545389473438263\n",
            "Training loss: 0.1577892154455185\n",
            "Training loss: 0.025058524683117867\n",
            "Training loss: 0.10438346862792969\n",
            "Class: a-eq:LR\n",
            "Accuracy: 2/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 94/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 3/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 169/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 163/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 38/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 129/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 75/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 15/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8200/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 236/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 248/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 6/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 87/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 43/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 11/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 9/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 306/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 809/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 10/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 111/116\n",
            "\n",
            "Validation loss: 0.44823203767494607\n",
            "F1 Score (Weighted): 0.8853420657176213\n",
            "None\n",
            "Training loss: 0.03477466478943825\n",
            "Training loss: 0.054041728377342224\n",
            "Training loss: 0.06213609129190445\n",
            "Training loss: 0.11656922847032547\n",
            "Training loss: 0.1680535525083542\n",
            "Training loss: 0.020944396033883095\n",
            "Training loss: 0.04719242826104164\n",
            "Training loss: 0.024393310770392418\n",
            "Training loss: 0.021901803091168404\n",
            "Training loss: 0.049929630011320114\n",
            "Training loss: 0.09948655962944031\n",
            "Training loss: 0.03751923888921738\n",
            "Training loss: 0.09190242737531662\n",
            "Training loss: 0.03391429781913757\n",
            "Training loss: 0.09734856337308884\n",
            "Training loss: 0.018853992223739624\n",
            "Training loss: 0.1361396461725235\n",
            "Training loss: 0.0665673315525055\n",
            "Training loss: 0.02832183614373207\n",
            "Training loss: 0.02228100225329399\n",
            "Training loss: 0.10851553082466125\n",
            "Training loss: 0.11259940266609192\n",
            "Training loss: 0.09440992027521133\n",
            "Training loss: 0.029151497408747673\n",
            "Training loss: 0.006171786226332188\n",
            "Training loss: 0.029821284115314484\n",
            "Training loss: 0.07116714119911194\n",
            "Training loss: 0.032953422516584396\n",
            "Training loss: 0.05329412594437599\n",
            "Training loss: 0.23317527770996094\n",
            "Training loss: 0.14018544554710388\n",
            "Training loss: 0.05146202817559242\n",
            "Training loss: 0.051406413316726685\n",
            "Training loss: 0.031191889196634293\n",
            "Training loss: 0.067397341132164\n",
            "Training loss: 0.16375698149204254\n",
            "Training loss: 0.009183351881802082\n",
            "Training loss: 0.02354312315583229\n",
            "Training loss: 0.0737379789352417\n",
            "Class: a-eq:LR\n",
            "Accuracy: 1/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 97/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 3/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 162/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 186/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 39/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 112/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 70/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 15/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8484/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 231/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 240/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 6/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 82/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 18/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 10/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 8/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 297/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 802/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 10/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 112/116\n",
            "\n",
            "Validation loss: 0.43204821293087053\n",
            "F1 Score (Weighted): 0.8967541059964268\n",
            "None\n",
            "Training loss: 0.02885134331882\n",
            "Training loss: 0.027908269315958023\n",
            "Training loss: 0.039547041058540344\n",
            "Training loss: 0.004782091360539198\n",
            "Training loss: 0.024862589314579964\n",
            "Training loss: 0.13147234916687012\n",
            "Training loss: 0.029209837317466736\n",
            "Training loss: 0.011031311005353928\n",
            "Training loss: 0.02995835244655609\n",
            "Training loss: 0.005340976174920797\n",
            "Training loss: 0.017091743648052216\n",
            "Training loss: 0.07487425953149796\n",
            "Training loss: 0.013498716056346893\n",
            "Training loss: 0.008192282170057297\n",
            "Training loss: 0.017508774995803833\n",
            "Training loss: 0.05406304821372032\n",
            "Training loss: 0.0627509132027626\n",
            "Training loss: 0.013634094968438148\n",
            "Training loss: 0.010522773489356041\n",
            "Training loss: 0.08799687772989273\n",
            "Training loss: 0.009161480702459812\n",
            "Training loss: 0.016606811434030533\n",
            "Training loss: 0.04907067120075226\n",
            "Training loss: 0.011017647571861744\n",
            "Training loss: 0.01417101826518774\n",
            "Training loss: 0.08413338661193848\n",
            "Training loss: 0.05567615106701851\n",
            "Training loss: 0.02279922179877758\n",
            "Training loss: 0.023506278172135353\n",
            "Training loss: 0.08920779824256897\n",
            "Training loss: 0.06357923150062561\n",
            "Training loss: 0.012518972158432007\n",
            "Training loss: 0.03305576369166374\n",
            "Training loss: 0.04646103084087372\n",
            "Training loss: 0.08219431340694427\n",
            "Training loss: 0.04696376994252205\n",
            "Training loss: 0.0534033328294754\n",
            "Training loss: 0.014882409945130348\n",
            "Class: a-eq:LR\n",
            "Accuracy: 2/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 100/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 3/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 157/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 176/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 40/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 120/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 74/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 15/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8404/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 232/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 250/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 5/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 85/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 22/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 10/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 8/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 298/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 802/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 10/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 112/116\n",
            "\n",
            "Validation loss: 0.4512814725555169\n",
            "F1 Score (Weighted): 0.893575386508602\n",
            "None\n",
            "Training loss: 0.005558522883802652\n",
            "Training loss: 0.026180995628237724\n",
            "Training loss: 0.09732636064291\n",
            "Training loss: 0.09613879024982452\n",
            "Training loss: 0.03150330111384392\n",
            "Training loss: 0.029908431693911552\n",
            "Training loss: 0.05184878781437874\n",
            "Training loss: 0.021203123033046722\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-651f3c0fb975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munscale_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "num_training_steps = num_epochs * len(train_dl)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "# weights = torch.tensor([64.44, 210.68, 33.40, 228.24, 46.92, 89.07, 22.07, 730.37, 9.83, 67.21, 163.51, 534.41, 377.78, 114.12, 1.37])\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    flow_model.train()\n",
        "    for batch in train_dl:\n",
        "        # # Custom Loss\n",
        "        # labels = batch.get(\"labels\")\n",
        "        # outputs = flow_model(**batch)\n",
        "        # logits = outputs.get(\"logits\")\n",
        "        # # compute custom loss (suppose one has 3 labels with different weights)\n",
        "        # loss = loss_fct(logits.view(-1, flow_model.config.num_labels), labels.view(-1))\n",
        "        # # End of Custom Loss\n",
        "\n",
        "        outputs = flow_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        if progress_bar.n % 20 == 0:\n",
        "          tqdm.write(f'Training loss: {loss}')\n",
        "\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(eval_dl)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    accuracy = accuracy_per_class(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
        "    print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCn4q14NIJKw"
      },
      "outputs": [],
      "source": [
        "flow_model.save_pretrained(project_dir + 'saved_models/entity_marking/flow-graph-optimized-parameter-model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYvuE40fNpcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44554e3-c613-4eb0-f564-51a17fa03db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: a-eq:LR\n",
            "Accuracy: 4/45\n",
            "\n",
            "Class: a-eq:RL\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: a:LR\n",
            "Accuracy: 100/127\n",
            "\n",
            "Class: a:RL\n",
            "Accuracy: 3/8\n",
            "\n",
            "Class: d:LR\n",
            "Accuracy: 157/190\n",
            "\n",
            "Class: d:RL\n",
            "Accuracy: 179/225\n",
            "\n",
            "Class: f-comp:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-comp:RL\n",
            "Accuracy: 38/54\n",
            "\n",
            "Class: f-eq:LR\n",
            "Accuracy: 122/221\n",
            "\n",
            "Class: f-eq:RL\n",
            "Accuracy: 0/6\n",
            "\n",
            "Class: f-part-of:LR\n",
            "Accuracy: 75/128\n",
            "\n",
            "Class: f-part-of:RL\n",
            "Accuracy: 15/19\n",
            "\n",
            "Class: f-set:LR\n",
            "Accuracy: 0/3\n",
            "\n",
            "Class: f-set:RL\n",
            "Accuracy: 0/2\n",
            "\n",
            "Class: non-edge\n",
            "Accuracy: 8388/9109\n",
            "\n",
            "Class: o:LR\n",
            "Accuracy: 233/252\n",
            "\n",
            "Class: o:RL\n",
            "Accuracy: 246/303\n",
            "\n",
            "Class: t-comp:LR\n",
            "Accuracy: 7/20\n",
            "\n",
            "Class: t-comp:RL\n",
            "Accuracy: 83/110\n",
            "\n",
            "Class: t-eq:LR\n",
            "Accuracy: 24/63\n",
            "\n",
            "Class: t-part-of:LR\n",
            "Accuracy: 10/28\n",
            "\n",
            "Class: t-part-of:RL\n",
            "Accuracy: 9/10\n",
            "\n",
            "Class: t:LR\n",
            "Accuracy: 298/372\n",
            "\n",
            "Class: t:RL\n",
            "Accuracy: 806/852\n",
            "\n",
            "Class: v-tm:LR\n",
            "Accuracy: 10/12\n",
            "\n",
            "Class: v-tm:RL\n",
            "Accuracy: 112/116\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_, predictions, true_vals = evaluate(eval_dl)\n",
        "val_f1 = f1_score_func(predictions, true_vals)\n",
        "accuracy_per_class(predictions, true_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDV6OliBJL0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fff668e-71dc-4c03-84d5-f4fe2b773be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     a-eq:LR       0.44      0.09      0.15        45\n",
            "     a-eq:RL       0.00      0.00      0.00         3\n",
            "        a:LR       0.64      0.79      0.71       127\n",
            "        a:RL       0.60      0.38      0.46         8\n",
            "        d:LR       0.49      0.83      0.62       190\n",
            "        d:RL       0.78      0.80      0.79       225\n",
            "   f-comp:LR       0.00      0.00      0.00         3\n",
            "   f-comp:RL       0.73      0.70      0.72        54\n",
            "     f-eq:LR       0.44      0.55      0.49       221\n",
            "     f-eq:RL       0.00      0.00      0.00         6\n",
            "f-part-of:LR       0.39      0.59      0.47       128\n",
            "f-part-of:RL       0.58      0.79      0.67        19\n",
            "    f-set:LR       0.00      0.00      0.00         3\n",
            "    f-set:RL       0.00      0.00      0.00         2\n",
            "    non-edge       0.97      0.92      0.94      9109\n",
            "        o:LR       0.91      0.92      0.92       252\n",
            "        o:RL       0.70      0.81      0.75       303\n",
            "   t-comp:LR       0.41      0.35      0.38        20\n",
            "   t-comp:RL       0.66      0.75      0.71       110\n",
            "     t-eq:LR       0.39      0.38      0.38        63\n",
            "t-part-of:LR       0.33      0.36      0.34        28\n",
            "t-part-of:RL       1.00      0.90      0.95        10\n",
            "        t:LR       0.60      0.80      0.69       372\n",
            "        t:RL       0.93      0.95      0.94       852\n",
            "     v-tm:LR       0.56      0.83      0.67        12\n",
            "     v-tm:RL       0.90      0.97      0.93       116\n",
            "\n",
            "    accuracy                           0.89     12281\n",
            "   macro avg       0.52      0.56      0.53     12281\n",
            "weighted avg       0.90      0.89      0.89     12281\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "pred_vals = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "labeled_preds = [label_names[pred_val] for pred_val in pred_vals]\n",
        "labeled_trues = [label_names[true_val] for true_val in true_vals]\n",
        "\n",
        "print(classification_report(labeled_trues, labeled_preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_vals = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "labeled_preds = [label_names[pred_val].replace(\":LR\", \"\").replace(\":RL\", \"\") for pred_val in pred_vals]\n",
        "labeled_trues = [label_names[true_val].replace(\":LR\", \"\").replace(\":RL\", \"\") for true_val in true_vals]\n",
        "\n",
        "print(classification_report(labeled_trues, labeled_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeEBPUjNpMFq",
        "outputId": "2f350140-1e4d-40ea-9a6c-2c3bb39039c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           a       0.64      0.76      0.70       135\n",
            "        a-eq       0.67      0.12      0.21        48\n",
            "           d       0.61      0.81      0.70       415\n",
            "      f-comp       0.73      0.67      0.70        57\n",
            "        f-eq       0.44      0.54      0.48       227\n",
            "   f-part-of       0.42      0.63      0.50       147\n",
            "       f-set       0.00      0.00      0.00         5\n",
            "    non-edge       0.97      0.92      0.94      9109\n",
            "           o       0.80      0.87      0.84       555\n",
            "           t       0.81      0.90      0.85      1224\n",
            "      t-comp       0.63      0.69      0.66       130\n",
            "        t-eq       0.39      0.38      0.38        63\n",
            "   t-part-of       0.49      0.50      0.49        38\n",
            "        v-tm       0.86      0.95      0.90       128\n",
            "\n",
            "    accuracy                           0.89     12281\n",
            "   macro avg       0.60      0.63      0.60     12281\n",
            "weighted avg       0.90      0.89      0.89     12281\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1znlCQDrrnmz-FmOW7EgHMIsNtCOg--_T",
      "authorship_tag": "ABX9TyPp/HRoMKbGk2ji2y0/Sdlr",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c87ed0a7d4943adbb98ac64e93a6d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f15aa55f1244c2f9c6c743a662dd0fa",
              "IPY_MODEL_82c749109b874b33911f7436086182b7",
              "IPY_MODEL_6524698e55e445a1a83d998277d034ce"
            ],
            "layout": "IPY_MODEL_19725ffb27e044ca923c86d5f6bbef28"
          }
        },
        "9f15aa55f1244c2f9c6c743a662dd0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c379ef96c149ecb3bfd992ecdaf726",
            "placeholder": "",
            "style": "IPY_MODEL_dd3de8e79f1f409c865b3e152aefefe2",
            "value": " 92%"
          }
        },
        "82c749109b874b33911f7436086182b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66f0c9c09074058bca4f82b3403ff84",
            "max": 7680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2755a32e58445a3afb870ec3f6ba2bb",
            "value": 7065
          }
        },
        "6524698e55e445a1a83d998277d034ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e84b0e566b4ee4acb1256e19401ef0",
            "placeholder": "",
            "style": "IPY_MODEL_88976ac245fa496bb8e5963010fcf25a",
            "value": " 7065/7680 [40:20&lt;03:17,  3.12it/s]"
          }
        },
        "19725ffb27e044ca923c86d5f6bbef28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c379ef96c149ecb3bfd992ecdaf726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3de8e79f1f409c865b3e152aefefe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a66f0c9c09074058bca4f82b3403ff84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2755a32e58445a3afb870ec3f6ba2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57e84b0e566b4ee4acb1256e19401ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88976ac245fa496bb8e5963010fcf25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}